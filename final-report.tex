% Project final report length limit: 10 pages, single-column standard latex.
% Due date May 13. This is a strict deadline as we need to finish grading by the final grades
% due date. Final project and poster presentation account for 40% of the the grade.
% Pre-proposal accounted for 1% of grade.
\documentclass[a4paper, 10pt]{article}

\usepackage{caption}
\usepackage{float}
\usepackage{hyperref}
\usepackage{xcolor}
\definecolor{commentgreen}{RGB}{2,112,10}
\definecolor{eminence}{RGB}{108,48,130}
\definecolor{weborange}{RGB}{255,165,0}
\definecolor{frenchplum}{RGB}{129,20,83}
\usepackage{listings}
\lstset {
    language=C++,
    frame=tb,
    tabsize=4,
    showstringspaces=false,
    numbers=left,
    %upquote=true,
    commentstyle=\color{commentgreen},
    keywordstyle=\color{eminence},
    stringstyle=\color{red},
    basicstyle=\small\ttfamily, % basic font setting
    emph={int,char,double,float,unsigned,void,bool},
    emphstyle={\color{blue}},
    escapechar=\&,
    % keyword highlighting
    classoffset=1, % starting new class
    otherkeywords={>,<,.,;,-,!,=,~},
    morekeywords={>,<,.,;,-,!,=,~},
    keywordstyle=\color{weborange},
    classoffset=0,
}

% We can define some other document properties too!
\author{Rashad Gover}
\date{\today}
\title{Exploring Parallel Programming in Haskell}

\begin{document}

\maketitle

\newpage
\tableofcontents

\newpage

\begin{abstract}
  In this report, we will explore parallel computation in the pure functional language \textbf{\textit{Haskell}}.
\end{abstract}

\section{Brief Introduction to Haskell}
Haskell is a declarative, functional programming language invented in 1971 by a group of programming language researchers for the purpose of exploring the design space of functional languages. Unlike imperative languages which are based on turing machines and embrace state, Haskell and other pure functional languages are based on the lambda calculus, invented by Turing's professor Alonzo Church, where state is dropped in favor of mathematical functions. At a high-level, a Haskell program is just a function that is composed of many smaller functions. On top of being a functional programming language, Haskell is also a strongly, statically typed language which eliminates an entire class of errors (type errors) at compile-time. 

Haskell has all the basic features that you would expect from any programming language like variables, function declaration,  and a module system for decoupling code. Haskell also has more interesting features like type inferenece, user defined types, pattern matching, type classes, lazy evaluation by default, and monads for modelling side-effects without compromising purity. These traits, besides laziness, make Haskell a prime candidate for implementing parallel algorithms. The declarative nature of Haskell allows the user to focus on the problem at hand instead of the low-level details such as state, the order in which statements are declared, and memory management.  Much of the burden that is usually placed on the shoulders of the programmer is pushed to the advanced compiler, which makes Haskell more "ergonomic" in my opinion. To show this, let's implement a program in C++ and Haskell that takes in an array or list, repspectively, and increments each value, doubles it, and then prints the values. The implementation in C++ would look something like this:

\begin{lstlisting}[language=C++, caption=C++ example]
#include <iostream>
int main() {
  int arrLength = 5;
  int arr [] = {1, 2, 3, 4, 5};
  for (int i = 0; i < arrLength; i++) {
    arr[i] += 1;
    arr[i] *= 2;
    std::cout << arr[i] << " ";
  }
  return 0;
}
\end{lstlisting}

The Haskell implementation would look like so:

\begin{lstlisting}[language=Haskell, caption=Haskell example]
module Main where
list = [1, 2, 3, 4, 5]
incThenDouble x = (x + 1) * 2
answer = map incThenDouble list
main = print answer
\end{lstlisting}

As we can see, the Haskell implementation is much more concise than the C++ implementation. You may also notice that compared to the Haskell version, the C++ version looks much like a "recipe" where each step of transforming the array in to another must be described in detail: how long the array is, how to loop through the array, the types of the variables, etc. The Haskell version on the other hand is very declarative, and as a result looks a lot cleaner and readable. Obviously, this is a contrived example, but in my experience it seems to be the case more often than not that Haskell code looks more approachable compared to an imperative language.

\subsection{Fibonacci Sequence}
The Fibonacci sequence is a series of numbers where a number is the addition of the last two numbers, starting with 0, and 1. The serial implementation in Haskell is very straightforward. The following isn't the fastest implementation, but is probably the most idiomatic:

\begin{lstlisting}[language=Haskell, caption=Haskell Fibonacci]
module SerialFib where

nfib
  :: Int  -- The nth number in the fibonacci sequence that you want
  -> Int -- The result
nfib 0 = 0
nfib 1 = 1
nfib n = nfib (n-1) + nfib (n-2)
\end{lstlisting}

We pattern match on the value of the integer: if the value is 0 return 0, and if it is 1 return 1. Otherwise, return the sum of fib of the previous fibonacci number and the fibonacci before the previous one. 

The use of recursion has some performance implications. The memory performance of recursive functions in Haskell differs depending on whether or not the recursive function is \textbf{\textit{tail recursive}}. A recursive function is tail recursive if the final result of the recursive call is the final result of the function itself. If the result of the recursive call must be further processed (say, by adding 1 to it, or consing another element onto the beginning of it), it is not tail recursive. So in the case above, the function nfib is not tail recursive.

\subsection{Matrix Multiplication}

To represent matrix multiplication in Haskell, we use the \lstinline{Vector} data type over the more idiomatic \lstinline{List} data type. This is to enhance the performance of the serial program since \lstinline{List} in Haskel is a lazy data structure,  while a \lstinline{Vector} value represents an \textbf{\textit{unboxed array}} under the hood and thus has an \textit{O(1)} length operation and data access.

\begin{lstlisting}[language=Haskell, caption=Haskell Fibonacci]
module SerialMatMul where

import Data.Vector (Vector(..), (!))
import qualified Data.Vector as Vector

matMul
  :: (Eq a, Num a)
  => Vector (Vector a)
  -> Vector (Vector a)
  -> Either String (Vector (Vector a))
matMul a b
  | Vector.length a == 0 || Vector.length b == 0 = Left "Empty matrices can't be used"
  | not (isConsistentMatrix a) || not (isConsistentMatrix b) = Left "The dimensions of the matrices are inconsistent"
  | numOfCol a /= numOfRow b = Left "These matrices are incompatible for multiplication"
  | otherwise = Right $ mul a b
  where
    numOfCol m = Vector.length $ Vector.head m
    numOfRow m = Vector.length m
\end{lstlisting}

Ideally, to leverage the advanced type sytem of Haskell we would encode the length of the vectors in their types. The compiler would then be able to automatically handle any cases in which the dimensions of the matrices represented as vectors don't match up correctly. This is known as \textbf{\textit{type-level programming}} and it allows the programmer to encode information in types to provide more information for the compiler and further constrain the number of unwanted outcomes. I opted for the above implementation due to ease of implementation and better performance, but needed to add guards to check the dimensions of the matrices at the value-level.

\subsection{Benchmarking}
This section goes over Threadscope and benchmarks the two examples above. Fibonacci and Matrix Mutiplication.

\section{Parallel Haskell}

\subsection{Parallel Evaluation Strategies}
This section will breifly explain Strategies and the Eval monad, and the functions rpar and rseq.

\subsubsection{Fibonacci Implementation}
This section will have the results for the Fibonacci Sequence and Matrix Multiplication usingthe Par Monad.

\subsubsection{Results}
This section will have the results for the Fibonacci Sequence and Matrix Multiplication usingthe Par Monad.

\subsection{Dataflow Parallelism with monad-par}
This section will introduce the Par Monad and the concept of dataflow parallelism.

\subsubsection{Fibonacci Implementation}
This section will have the results for the Fibonacci Sequence and Matrix Multiplication usingthe Par Monad.

\begin{lstlisting}
module MonadParFib where

import Control.Monad.Par

nfib :: Int -> Par Int
nfib n = do
  firstComputation <- spawn (pfib (n - 1))
  secondValue <- pfib (n - 2)
  firstValue <- get firstComputation
  return (firstValue + secondValue)
\end{lstlisting}

\subsubsection{Results}
This section will have the results for the Fibonacci Sequence and Matrix Multiplication usingthe Par Monad.

\subsection{Regular Parallel Arrays}

\subsubsection{Matrix Multiplication Implementation}
This section will have the results for the Fibonacci Sequence and Matrix Multiplication usingthe Par Monad.

\subsubsection{Results}
This section will have the results for the Fibonacci Sequence and Matrix Multiplication usingthe Par Monad.

\subsection{Particle Simulation with Accelerate Library}
This section goes over the Accerlerate library and the idea of embedded DSLs withing Haskell, for which it
 is known for. In this section, HW2 particle simulation is used

\subsubsection{Particle Simulation}

\subsubsection{Multicore Results}
This section will have the results for the Fibonacci Sequence and Matrix Multiplication usingthe Par Monad.

\subsubsection{GPU Results}
This section goes over GPU programming in Accelerate. This will be pretty much the same
as the multicore programming in the above section because we can write programs for both platforms
with a single syntax! The syntax used to describe the parallel program is decoupled from the platform it runs on which is great.

\section{Honorable Mentions}


\section{Conclusion}
This section will rap up the results of the benchmarks and come to conclusion. Was climbing up the
 abstraction ladder worth the tradeoff in performance? Was the drop in performance of the Haskell implementations
 worth the better ergonomics? This could be argued, especially if the user isn't familiar with functional programming.
 Was the performance of the Haskell programs not that much of a difference from the C++ implementations? What do overhead costs look like?
 How does scaling compare between the two platforms? Weak and strong scaling.

\section{Prior Work \& Resources}

\end{document}